\section*{\revise{Limitations of NSC and alternatives}}
\label{sec:limitations}

\mikeNote{Reviewer 2 wants us to discuss all these limitations and compare NSC to other theories. We could do this in the Conclusions, but I thought a Limitations section right before the end would make more sense, so that we can end the paper on a high note with positive conclusions.

Here's a potential outline for this section. Just needs more sciency words.}

\revise{The role of sparse coding has been questioned in the brain 
\cite{SpanneJorntell2015}.
One issue that basically any code between local and dense can be labeled sparse
\cite{SpanneJorntell2015}. That's not a big deal because we're fine with that definition. We find it interesting that there is a sweet spot for the sparsity of the code, depending on population size and the complexity of the information that is being encoded. We previously showed this for \ac{MSTd} \cite{Beyeler2016}.
We have no doubt that the sparsity of the code might differ in different areas. For example, \ac{V1} seems to operate in a regime with an overcomplete basis set \cite{olshausen1997}. On the other hand, \ac{MSTd} seems to operate with a relatively small dictionary. We think this gives \ac{MSTd} an increased representational capacity which could lead to compact and multifaceted encodings of various perceptual variables
(see Discussion in \cite{Beyeler2016}).}

\revise{Then some people have questioned whether some regions are really sparse.
For one, there are the two examples raised in the Spanne article: basal ganglia and different layers of visual cortex. Turns out basal ganglia might not be too sparse. Turns out only Layer 2/3 in V1 might be sparse.}

\revise{The problem is that there is a problem with simulation studies:
If you study simple phenomena, you might get simple dynamics (this addresses a comment
by Reviewer 1). There's not much you can do, except focus on all attributes of the
population code, not just sparsity.
From Gao \cite{Gao2017}: Dimensionality reduction methods reveal a striking simplicity underlying such multi-neuronal data: they can be reduced to a low-dimensional space, and the resulting neural trajectories in this space yield a remarkably insightful dynamical portrait of circuit computation. This simplicity raises profound and timely conceptual questions. What are its origins and its implications for the complexity of neural dynamics? How would the situation change if we recorded more neurons? When, if at all, can we trust dynamical portraits obtained from measuring an infinitesimal fraction of task relevant neurons?}


\revise{Finally, there are other competing theories of brain function, 
such as compressed sensing \cite{GanguliSompolinsky2012}.
Compressed sensing works like this and that.
There's also predictive coding and free energy and blah blah blah,
but we don't want to talk about everyone and their grandmother.}

\revise{This leads to our final point: that we don't think the brain the does NSC
and only NSC.
This is just something we want to stress to please the reviewers.
We simply highlight NSC as a potential canonical computation - we found it pop up all
over the brain and are intrigued. However, we need more research to see this through.}


